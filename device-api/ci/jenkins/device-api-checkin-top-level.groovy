// Autogenerated
import hudson.model.*
pipeline {
  parameters {
    string(name: 'BRANCH', defaultValue: '$gitlabSourceBranch', description: 'Branch name to checkout')
    string(name: 'REPO_SSH_URL', defaultValue: 'git@gitlab.esperanto.ai:software/device-api.git', description: 'Repository URL')
    string(name: 'REPO_NAME', defaultValue: 'device-api', description: 'Repository name')
    string(name: 'COMPONENT_COMMITS', defaultValue: '', description: 'List of submodule-paths and their commits to checkout as part of the build. The formath is <SUBMODULE_PATH_1>:<COMMIT_1>,<SUBMODULE_PATH_2>:<COMMIT_2>')
    string(name: 'NODE', defaultValue: 'DISPATCHER', description: 'Node label where the job should run')
    string(name: 'TIMEOUT', defaultValue: '12', description: 'Timeout (in hours)')
    booleanParam(name: 'HARD_CLEAN', defaultValue: 'true', description: 'If set to 1, removes all the workspace at the end of the regression')
    booleanParam(name: 'CHECK_ON_TOP_OF_MASTER', defaultValue: 'true', description: 'when true this executes checks that ensures Merge Request has merged origin/master with their MR at the time the MR was submiteted')
    string(name: 'SW_PLATFORM_BRANCH', defaultValue: 'origin/master', description: 'SW-Platform branch to track')
    string(name: 'INPUT_TAGS', defaultValue: '', description: 'Parameter to receive tags from parent pipelines')
  }
  agent {
    label "${params.NODE}"
  }
  options {
    buildDiscarder(logRotator(daysToKeepStr: '15', artifactDaysToKeepStr: '15'))
    gitLabConnection('Gitlab')
    timeout(time: "${params.TIMEOUT}", unit: "HOURS")
    timestamps()
    skipDefaultCheckout(true)
  }
  triggers {
    gitlab(triggerOnMergeRequest: true, branchFilterType: 'All')
  }
  environment {
    CHECK_CHILD_JOBS = " --commit-passed ${GIT_COMMIT}  --job-params \' \\\"COMPONENT_COMMITS\\\": \\\"${COMPONENT_COMMITS}\\\"}\' "
    PIPELINE_TAGS = "${INPUT_TAGS},"
  }
  stages {
    stage('CHECKOUT_SCM') {
      steps {
        updateGitlabCommitStatus name: JOB_NAME, state: 'pending'
        script {
          def seconds = -1
          retry(8) {
            seconds = seconds * 2 + 2
            sleep(time: seconds, unit: "SECONDS")
            scm_variables = checkout([
              $class: 'GitSCM',
              branches: [[name: BRANCH]],
              doGenerateSubmoduleConfigurations: false,
              extensions: [],
              submoduleCfg: [],
              userRemoteConfigs: [[
                credentialsId: 'aws_private_key',
                url: "${REPO_SSH_URL}"
              ]]
            ])
            env.GIT_COMMIT = scm_variables.get('GIT_COMMIT')
          }
        }
      }
    }
    stage('CHECK_MERGE_UP_TO_DATE') {
      when {
        expression {
          return sh(returnStatus: true, script: "${CHECK_ON_TOP_OF_MASTER}") == 0
        }
      }
      steps {
        sh 'git fetch ; git merge origin/master | grep Already && ( echo \"Branch is up to date with Origin/Master proceeding...\" ; exit 0 ) || ( echo \"Merge request is out of date with respect to origin/master. Please, rebase it and re-submit merge request\" ; exit 1 )'
      }
    }
    stage('DSL_JOB') {
      steps {
        build job:
          'meta-job',
          propagate: true,
          parameters: [
            string(name: 'BRANCH', value: "${BRANCH}"),
            string(name: 'REPO_SSH_URL', value: "${REPO_SSH_URL}"),
            string(name: 'REPO_NAME', value: "${REPO_NAME}"),
            string(name: 'INPUT_TAGS', value: "${env.PIPELINE_TAGS}")
          ]
      }
    }
    stage('PARALLEL0') {
      parallel {
        stage('JOB_BASE_INTEGRATION') {
          steps {
            build job:
              'sw-platform/tools-and-utils/pipelines/sw-platform-basic-integration',
              propagate: true,
              parameters: [
                string(name: 'BRANCH', value: "${SW_PLATFORM_BRANCH}"),
                string(name: 'COMPONENT_COMMITS', value: "${COMPONENT_COMMITS},common-apis/device-api:${BRANCH}"),
                string(name: 'INPUT_TAGS', value: "${env.PIPELINE_TAGS}")
              ]
          }
        }
        stage('JOB_GLOW_OPERATORS') {
          steps {
            build job:
              'sw-platform/host-sw-integration/pipelines/dnn-lib/glow-operators-ci-minimal-etrt-devfw-sysemu',
              propagate: true,
              parameters: [
                string(name: 'BRANCH', value: "${SW_PLATFORM_BRANCH}"),
                string(name: 'COMPONENT_COMMITS', value: "${COMPONENT_COMMITS},common-apis/device-api:${BRANCH}"),
                string(name: 'PYTEST_RETRIES', value: '2'),
                string(name: 'TIMEOUT', value: '3'),
                string(name: 'INPUT_TAGS', value: "${env.PIPELINE_TAGS}")
              ]
          }
        }
        stage('JOB_RUNTIME') {
          steps {
            build job:
              'sw-platform/runtime-integration/pipelines/runtime-checkin-tests',
              propagate: true,
              parameters: [
                string(name: 'BRANCH', value: "${SW_PLATFORM_BRANCH}"),
                string(name: 'COMPONENT_COMMITS', value: "${COMPONENT_COMMITS},common-apis/device-api:${BRANCH}"),
                string(name: 'PYTEST_RETRIES', value: '2'),
                string(name: 'INPUT_TAGS', value: "${env.PIPELINE_TAGS}")
              ]
          }
        }
      }
    }
  }
  post {
    success {
      updateGitlabCommitStatus name: JOB_NAME, state: 'success'
    }
    failure {
      updateGitlabCommitStatus name: JOB_NAME, state: 'failed'
    }
    aborted {
      updateGitlabCommitStatus name: JOB_NAME, state: 'canceled'
    }
    cleanup {
      sh 'for pid in $(lsof +D . 2> /dev/null | grep .nfs | awk \"{print $2}\" ); do kill -9 $pid; done'
      sh "if [ ${HARD_CLEAN} = true ]; then rm -rf * && rm -rf .[^.]*; fi"
    }
  }
}